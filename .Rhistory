var(x)
y <- 5*x^2 - x + 0.1*rnorm(n) # Create simulated response.
x <- sort(runif(n))           # Create 100 values between 0 and 1.
x
n <- 100
x <- sort(runif(n))           # Create 100 values between 0 and 1.
x
y <- 5*x^2 - x + 0.1*rnorm(n) # Create simulated response.
plot(x,y)                     # Plot the data.
reg.model <- lm(y~x+I(x^2))   # Fit the regression model.
lines(x,fitted(reg.model),col="red") # Plot the fitted function.
x         <- x+1000 # Add 1000 to each x.
plot(x,y)   # Plot the data.
reg.model <- lm(y~x+I(x^2)) # Fit the regression model.
lines(x,fitted(reg.model),col="red") # Plot the fitted function.
#a) Which one is correct
##i)
5-7/8
##ii)
5-(7/8)
##ii)
(5-7)/8
#g) Which one is correct
##i)
(1/56)^(1/4)
#ii)
56^(-1/4)
#a) Define a new variable x taking the value 1.
x<-1
#b) Update x to take the value x/2+1/x
x<-x/2+1/x
#c) Repeat the update from the previous part.
x<-x/2+1/x
x<-x/2+1/x
x<-x/2+1/x
x<-x/2+1/x
x<-x/2+1/x
#d) Test that the above tends to the square root of 2.
x
sqrt(2)
#a) Define a new variable x taking the value 1.
x<-1
#b) Update x to take the value x/2+1/x
x<-x/2+1/x
x
#c) Repeat the update from the previous part.
x<-x/2+1/x
x
?sample()
#a)
test <- sample(x=c(1,2,3,4,5,6,7,8,9,10), size=4, replace=TRUE)
test
c(1,2,3,4,5,6,7,8,9,10)
1:10
?rnorm()
#b)
n <- 20
k <- rnorm(n=n, mean=1, sd=0.8)
k
###bonus:
set.seed(1547)
k <- rnorm(n=n, mean=1, sd=0.8)
k
a <- sample(x=c(TRUE, FALSE), size=1)
b <- sample(x=c(TRUE, FALSE), size=1)
a
b
!TRUE
a
a==FALSE
l<-5
l==5
l==6
l!=5
l!=100
###Test if it works
a<-TRUE
b<-TRUE
c<-a==b
c
a<-FALSE
b<-TRUE
c<-a==b
c
###Test if it works
a<-TRUE
b<-TRUE
c<-(a & b) | (!a & !b)
c
(a & b)
(!a & !b)
a<-TRUE
b<-FALSE
c<-(a & b) | (!a & !b)
c
(a & b)
(!a & !b)
a<-FALSE
b<-TRUE
c<-(a & b) | (!a & !b)
c
a<-FALSE
b<-FALSE
c<-(a & b) | (!a & !b)
c
###Test if it works
a<-TRUE
b<-TRUE
c<-!((a & !b) | (b & !a))
c
a<-TRUE
b<-FALSE
c<-!((a & !b) | (b & !a))
c
(a & !b)
###Test if it works
a<-TRUE
b<-TRUE
(a & !b)
(b & !a)
z <- sample(1:10, 1)
z
z%%2
11%%2
zeven <- z%%2==0
y <- sample(1:100, 1)
y
y
z
68/8
68%%8
ydevis <- y%%z==0
ydevis
y%%z
(y%%z)%%z
y%%z
z
(y%%z)%%z
(y%%z)%%z==0
#d) What do the results of the following line of code tell us?
14 %/% 4
###Question 1###
###part 1)
sum(1:10)
###part 2)
###For the second part, which option is correct?
sum((1:100)^2) #option 1
sum(1:100)^2   #option 2
sum(1:100^2)   #option 3
sum(1:100)
1:100^2
###Question 2###
x <- seq(1, 5, by=0.3)
?seq
x
###1) finding the mean:
mean(x)
###2) finding standard deviation
sd(x)
###3) standardise x
x<-(x-mean(x))/sd(x)
###4) check that the mean is zero
mean(x)
###5) check that standard deviation is 1
sd(x)
###Question 2###
x <- seq(1, 5, by=0.3)
x
###1) finding the mean:
mean(x)
###2) finding standard deviation
sd(x)
###3) standardise x
x<-scale(x)
###4) check that the mean is zero
mean(x)
###5) check that standard deviation is 1
sd(x)
x <- rnorm(100, mean=1, sd=1)
x
###Things we need
###1) sample size n
n <- 100
###2) mean of x x.bar
x.bar <- 1/n *sum(x)
x.bar <- mean(x)
###3) the difference between x and x.bar
differences <- x-x.bar
sx2<-1/(n-1)*sum((x-x.bar)^2)
###5) calculate t!
t<-sqrt(n)*x.bar/sqrt(sx2)
t
###6) compare to t.test()
t.test(x)
###Question 4
###part 1)
sum(2^(0:9)) ###option 1
sum(2^0:9)   ###option 2
sum(2)^(0:9) ###option 3
sum(2)
sum(1/2^(1:1e5))   ###option 2
sum((1/2)^(1:1e5)) ###option 1
sum(1^2:1e5/2)     ###option 3
x<-rnorm(100)
mean(x)
median(x)
x<-rnorm(100)
mean(x)
median(x)
x<-rnorm(100)
mean(x)
median(x)
x<-rnorm(100)
mean(x)
median(x)
x <- rcauchy(100)
mean(x)
median(x)
x <- rcauchy(100)
mean(x)
median(x)
x <- rcauchy(100)
mean(x)
median(x)
x <- rcauchy(100)
mean(x)
median(x)
x <- rcauchy(100)
mean(x)
median(x)
###part 2)
x <- rcauchy(100)
mean(x)
median(x)
x
sort()
sort(x)
###part 3)
###cut off the first 10 and the last 10 observations
x.trimmed<-sort(x)[11:90]
##and then calculate mean
mean(x.trimmed)
###Does anyone know another/quicker way?###
mean(x,trim=0.1)
###Question 6
###1) create the vector u
u <- 1:100
###Can you think of alternative ways of creating u?###
u <- seq(from=1,to=100,by=1)
u<55
u[u<55]
a <- c(TRUE,FALSE)
a
b <- c(FALSE,FALSE)
b
c <- (a & !b)
a
!b
a & !b
c <- (a & !b)
c
d <- !(a | b)
a
b
a | b
!(a | b)
d <- !(a | b)
d
###sequence 1
1:10
###sequence 2
rep(1:3, times = 4)
###sequence 3
rep(1:3,each = 2)
###sequence 4
c(1:20,19:1)
###sequence 5
(1:10)^2
###sequence 6
2^(0:10)
###1) create P
P<-diag(c(1,5,1,7,9))
P
P[1,4]<- -1
P[3,1]<- 3
source("C:/Users/Ivona Voroneckaja/Desktop/Desktop stuff/Lab2_Ivona.R", echo=TRUE)
###1) create P
P     <- diag(c(1,5,1,7,9))
P[1,4]<- -1
P[3,1]<- 3
P
###2) print the first row and the second column of P
P[1,]
P[,2]
###3) print the submatrix that consists of the first three
###rows and first two columns of P
P[1:3,1:2]
###BONUS: print rows 1 and 3
P[c(1,3),]
###4) compute transpose of P
t(P)
###5) compute inverse of P
solve(P)
###6) replace the first row of P by (1, 2, 3, 4, 5)
P[1,]<-1:5
P
###7) replace all non-zero entries of the matrix P by 1
P[P!=0]<-1
P
###1) create A and b
A <- rbind(c( 1, 2, 3),
c( 2, 20, 26),
c(3, 26, 70))
b <- c(4, 52, 31)
###2) use solve() to find z
solve(A,b)
solve(A)%*%b
###3) use chol and t to compute the Choleski factor L
L<- t(chol(A))
###4) verify that LL^T is (except for rounding errors) identical to A
L%*%t(L)
A
###5) compute v
v <- solve(L)%*%b
###1) create A and b
A <- rbind(c( 1, 2, 3),
c( 2, 20, 26),
c(3, 26, 70))
b <- c(4, 52, 31)
###2) use solve() to find z
solve(A,b)
solve(A)%*%b
###3) use chol and t to compute the Choleski factor L
L<- t(chol(A))
###4) verify that LL^T is (except for rounding errors) identical to A
L%*%t(L)
###5) compute v
v <- solve(L)%*%b
v <- forwardsolve(L,b)
###6) calculate z using previous steps
z <- solve(t(L))%*%v
###7) compute the square of the product of the diagonal entries of L
prod(diag(L))^2
det(A)
15/60
20/60
47+15
library(corrplot,quietly = TRUE)
library(Hmisc)
library(corrplot,quietly = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot,quietly = TRUE)
library(Hmisc)
setwd("C:/Users/Ivona Voroneckaja/Desktop/Consulting Work/WellFish/November")
data            <-read.csv("211101 WellFish database with 2021 Model Output Unsecured.csv",na.strings = " ")
biomarker_range <-45:77
biomarkers    <-matrix(nrow=nrow(data),ncol=length(biomarker_range))
biomarkers[,17][biomarkers[,17]<0]<-NA
for(i in 1:ncol(biomarkers)) biomarkers[,i]<-as.numeric(data[,biomarker_range[1]-1+i])
labels              <-names(data[,biomarker_range])
colnames(biomarkers)<-labels
cors                <-round(cor(biomarkers, use = "complete.obs"),2)
write.table(cors,"rawcors.csv",sep=",",row.names = TRUE,col.names = TRUE)
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
cor2   <-rcorr(biomarkers,type="pearson")
results<-flattenCorrMatrix(cor2$r, cor2$P)
write.table(results,"results.csv",sep=",")
biomarkers+1e-6
head(biomarkers+1e-6)
cor2   <-rcorr(biomarkers+10e-6,type="pearson")
head(log(biomarkers+10e-6))
min(biomarkers[,17])
min(biomarkers[,17],na.rm = T)
setwd("C:/Users/Ivona Voroneckaja/Desktop/Consulting Work/WellFish/November")
data            <-read.csv("211101 WellFish database with 2021 Model Output Unsecured.csv",na.strings = " ")
biomarker_range <-45:77
biomarkers    <-matrix(nrow=nrow(data),ncol=length(biomarker_range))
biomarkers[,17][biomarkers[,17]<0]<-NA
min(biomarkers[,17],na.rm = T)
rm(list=ls())
setwd("C:/Users/Ivona Voroneckaja/Desktop/Consulting Work/WellFish/November")
data            <-read.csv("211101 WellFish database with 2021 Model Output Unsecured.csv",na.strings = " ")
biomarker_range <-45:77
biomarkers    <-matrix(nrow=nrow(data),ncol=length(biomarker_range))
biomarkers[,17][biomarkers[,17]<0]<-NA
summary(biomarkers[,17])
data            <-read.csv("211101 WellFish database with 2021 Model Output Unsecured.csv",na.strings = " ")
biomarker_range <-45:77
biomarkers    <-matrix(nrow=nrow(data),ncol=length(biomarker_range))
for(i in 1:ncol(biomarkers)) biomarkers[,i]<-as.numeric(data[,biomarker_range[1]-1+i])
biomarkers[,17][biomarkers[,17]<0]<-NA
summary(biomarkers[,17])
for(i in 1:ncol(biomarkers)) biomarkers[,i]<-as.numeric(data[,biomarker_range[1]-1+i])
biomarkers[,17][biomarkers[,17]<0]<-NA
labels              <-names(data[,biomarker_range])
data            <-read.csv("211101 WellFish database with 2021 Model Output Unsecured.csv",na.strings = " ")
biomarker_range <-45:77
biomarkers    <-matrix(nrow=nrow(data),ncol=length(biomarker_range))
for(i in 1:ncol(biomarkers)) biomarkers[,i]<-as.numeric(data[,biomarker_range[1]-1+i])
biomarkers[,17][biomarkers[,17]<0]<-NA
labels              <-names(data[,biomarker_range])
colnames(biomarkers)<-labels
cors                <-round(cor(biomarkers, use = "complete.obs"),2)
write.table(cors,"rawcors.csv",sep=",",row.names = TRUE,col.names = TRUE)
write.table(cors,"rawcors.csv",sep=",",row.names = TRUE,col.names = TRUE)
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
cor2   <-rcorr(biomarkers,type="pearson")
results<-flattenCorrMatrix(cor2$r, cor2$P)
write.table(results,"results.csv",sep=",")
cor2   <-rcorr(log(biomarkers+10e-6),type="pearson")
log(biomarkers+10e-6)
apply(log(biomarkers+10e-6),2,summary)
log(10e-6)
this<-log(biomarkers+10e-6)
head(this)
log(NA)
which(is.nan(this))
summary(biomarkers[,17])
apply(biomarkers,2,summary)
cor2   <-rcorr(log(biomarkers+10e-6),type="pearson")
results<-flattenCorrMatrix(cor2$r, cor2$P)
write.table(results,"results.csv",sep=",")
library(ggfortify)
install.packages("ggfortify")
shiny::runApp('C:/Users/Ivona Voroneckaja/Desktop/Consulting Work/Inspiring Scoland/MapApp')
shiny::runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp()
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/Consulting Work/Capital Credit Union/ShinyApp')
shiny::runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
setwd("C:/Users/Ivona Voroneckaja/Desktop/MoE/MoE")
data<-read.csv("data_mcycle_stand.csv",header=FALSE)
plot(data[,3],data[,1],pch=20,ylab="Acceleration (g)",xlab="Time (ms)")
m<-gam(V1~s(V3),data=data)
###Property prices data investigation.
library(mgcv)
m<-gam(V1~s(V3),data=data)
beta<-coef(m)    ###parameter estimates
V   <-vcov(m) ###cov matrix
###simulate a number of parameter vectors:
num_beta_vecs <- 10000
Cv <- chol(V)
set.seed(1)
nus <- rnorm(num_beta_vecs * length(beta))
beta_sims <- beta + t(Cv) %*% matrix(nus, nrow = length(beta), ncol = num_beta_vecs)
dim(beta_sims)
###Check that the standard erorrs are similar
d_beta <- cbind(summary(m)$se, apply(beta_sims, 1, sd))
head(d_beta)
plot(d_beta[, 1], d_beta[, 2],
xlab = "Calculated SE",
ylab = "Simulated SE")
abline(0, 1)
###Simulate observations
###Sample from original observations with replacement
n_obs   <- 500
sim_idx <- sample.int(nrow(data), size = n_obs, replace = TRUE)
sim_dat <- data[sim_idx, ]
###Calculate linear predictors
covar_sim   <- predict(m, newdata = sim_dat, type = "lpmatrix")
linpred_sim <- covar_sim %*% beta_sims
###Gaussian used,so inv limnk is the identity
invlink <- function(x) x
###Obtain expected values
exp_val_sim <- invlink(linpred_sim)
###Simulate y:
y_sim <- matrix(rnorm(n = prod(dim(exp_val_sim)),
mean = exp_val_sim,
sd = sqrt(summary(m)$scale)),
nrow = nrow(exp_val_sim),
ncol = ncol(exp_val_sim))
dim(y_sim) ##(i,j) contains the i'th simulated observation's simulated response under parameter vector j
###Find a 95% prediction interval:
pred_int_sim <- apply(y_sim, 1, quantile, prob = c(.025, 0.975))
dim(pred_int_sim)
###Plot:
par(mfrow=c(1,1))
plot(V1~V3,data=data,ylim=c(min(pred_int_sim),max(pred_int_sim)),ylab="Acceleration (g)",xlab="Time (ms)")
sim_dat_x0ord <- order(sim_dat$V3)
lines(sim_dat$V3[sim_dat_x0ord], pred_int_sim[1L, sim_dat_x0ord], col = 2, lwd = 2)
lines(sim_dat$V3[sim_dat_x0ord], pred_int_sim[2L, sim_dat_x0ord], col = 2, lwd = 2)
dim(y_sim) ##(i,j) contains the i'th simulated observation's simulated response under parameter vector j
m$fitted.values
lines(sim_dat$V3,m$fitted.values)
m$fitted.values
lines(data$V3,m$fitted.values)
lines(data$V3,m$fitted.values,lwd=2,col="red")
shiny::runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
runApp('C:/Users/Ivona Voroneckaja/Desktop/MoE/RJ R Code/ShinyAppNew')
